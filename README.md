# RNN-LSTM: From Applications to Modeling Techniques and Beyond - Systematic Review

**Abstract**
<br>
Long Short-Term Memory (LSTM) networks are pivotal in processing sequential data with long-term dependencies. Despite their popularity, the challenge of effectively initializing and optimizing LSTM models persists, often hindering model performance and accuracy. This study systematically reviews the breadth of literature to answer how weight initialization and optimization techniques can be used to bolster LSTM performance. Utilizing the PRISMA methodology, 95 peer-reviewed articles spanning 2018-2023 are analyzed. Our analysis encompasses numerous modeling techniques, offering a comprehensive overview across various application domains. This paper stands out by comprehensively analyzing modeling techniques, datasets, evaluation metrics, programming languages, and the diverse applications and domains of LSTM networks. Our findings provide a roadmap for researchers and practitioners to enhance LSTM networks and achieve superior results.

**Research Highlights**
* In-depth four-step approach to methodically include studies concerning the initialization and optimization of LSTM weights.
* Extensive discussion on the current domains and applications into which LSTM is used.
* An extensive analysis of various weight initialization strategies in RNN-LSTM networks.
* Comprehensively surveys the different optimization algorithms used in optimizing RNN-LSTM networks.
* Identified the current dominated techniques and tools in LSTM models development, including the preferred and most used programming languages and the most used evaluation metrics.

**Data Availability**
<br>
The Microsoft Excel file utilized for this systematic literature review will be made publicly accessible in this repository following the acceptance of our manuscript.
